{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a3f2d635-f57a-4bdf-8df4-e02d6a8a973f",
   "metadata": {},
   "source": [
    "# **AI-Powered Fleet Optimization & Road Incident Prediction for Smart Transportation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d531f4-9469-4e7b-87cf-bf3184270684",
   "metadata": {},
   "source": [
    "## **Objective**\n",
    "Develop an end-to-end ML system that:\n",
    "1.\tPredicts potential route incidents (accidents, breakdowns, slowdowns).\n",
    "2.\tOptimizes fleet scheduling & vehicle assignment in real time.\n",
    "3.\tAutomatically re-routes vehicles during disruptions.\n",
    "This is an enterprise-level ML pipeline used by large-scale logistics companies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec773bb-78fb-4a95-8015-7dd22569d1b1",
   "metadata": {},
   "source": [
    "# **Phase 1: Real-Time Data Integration Layer**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde3f722-48d3-4d9c-b823-973f27eee15a",
   "metadata": {},
   "source": [
    "This phase simulates real-time fleet data such as GPS location, vehicle speed,\n",
    "engine health, traffic conditions, and weather data. The generated stream\n",
    "acts as the live input source for downstream ML models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01332c53-28b0-4f9f-b0aa-1d63346d3cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder created: phase1_realtime_stream\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "phase1_dir = \"phase1_realtime_stream\"\n",
    "\n",
    "os.makedirs(phase1_dir, exist_ok=True)\n",
    "\n",
    "print(\"Folder created:\", phase1_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaad0d72-12be-429a-af83-5b6d4eddd50c",
   "metadata": {},
   "source": [
    "### **Configuration Management**\n",
    "Defines centralized configuration parameters such as data paths,\n",
    "streaming frequency, and simulation constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfed8a7c-0246-453a-afe1-bffd52aafe52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing phase1_realtime_stream/config.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile phase1_realtime_stream/config.py\n",
    "# =========================\n",
    "# Streaming Configuration\n",
    "# =========================\n",
    "\n",
    "STREAM_INTERVAL = 2  # seconds\n",
    "\n",
    "# Starting GPS location (Hyderabad)\n",
    "START_LAT = 17.3850\n",
    "START_LON = 78.4867\n",
    "\n",
    "SPEED_RANGES = {\n",
    "    \"highway\": (60, 100),\n",
    "    \"urban\": (20, 50),\n",
    "    \"rural\": (30, 60)\n",
    "}\n",
    "\n",
    "WEATHER_TYPES = [\"clear\", \"rain\", \"fog\"]\n",
    "\n",
    "WEATHER_RISK = {\n",
    "    \"clear\": 0.1,\n",
    "    \"rain\": 0.6,\n",
    "    \"fog\": 0.8\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02a3fa7-febe-47ff-8b36-7775c9cdadbe",
   "metadata": {},
   "source": [
    "### **Vehicle Master Dataset**\n",
    "Stores static vehicle information including capacity, engine type,\n",
    "and vehicle category used during optimization and prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1367ef4-036d-4c91-80a4-342a3bc00dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing phase1_realtime_stream/vehicle_master.csv\n"
     ]
    }
   ],
   "source": [
    "%%writefile phase1_realtime_stream/vehicle_master.csv\n",
    "vehicle_id,vehicle_type,capacity,engine_type\n",
    "V101,Truck,1000,Diesel\n",
    "V102,Van,700,Petrol\n",
    "V103,Truck,1200,Diesel\n",
    "V104,Van,650,Petrol\n",
    "V105,Truck,1500,Diesel\n",
    "V106,Van,600,Petrol\n",
    "V107,Truck,1300,Diesel\n",
    "V108,Van,750,Petrol\n",
    "V109,Truck,1400,Diesel\n",
    "V110,Van,800,Petrol\n",
    "V111,Truck,1000,Diesel\n",
    "V112,Van,700,Petrol\n",
    "V113,Truck,1200,Diesel\n",
    "V114,Van,650,Petrol\n",
    "V115,Truck,1500,Diesel\n",
    "V116,Van,600,Petrol\n",
    "V117,Truck,1300,Diesel\n",
    "V118,Van,750,Petrol\n",
    "V119,Truck,1400,Diesel\n",
    "V120,Van,800,Petrol\n",
    "V121,Truck,1000,Diesel\n",
    "V122,Van,700,Petrol\n",
    "V123,Truck,1200,Diesel\n",
    "V124,Van,650,Petrol\n",
    "V125,Truck,1500,Diesel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c58a2bf-e23f-4f9f-99ad-090df83c441c",
   "metadata": {},
   "source": [
    "### **Past Accident Database**\n",
    "Contains historical accident coordinates and severity levels.\n",
    "Used for training incident prediction models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08d39b90-b330-4836-9c7f-26fd82b37123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing phase1_realtime_stream/past_accidents.csv\n"
     ]
    }
   ],
   "source": [
    "%%writefile phase1_realtime_stream/past_accidents.csv\n",
    "latitude,longitude,severity\n",
    "17.3855,78.4869,High\n",
    "17.3872,78.4881,Medium\n",
    "17.3901,78.4905,Low\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1305d70e-c68a-4b55-bde2-1a504eb49224",
   "metadata": {},
   "source": [
    "### **Real-Time Fleet Data Generator**\n",
    "Simulates continuous streaming data for:\n",
    "- GPS coordinates\n",
    "- Vehicle speed\n",
    "- Engine health\n",
    "- Driver behavior\n",
    "- Traffic and weather conditions\n",
    "\n",
    "Acts as a substitute for Kafka in this implementation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f99bcc07-fd50-47ba-8f2d-322e086fef8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting phase1_realtime_stream/data_generator.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile phase1_realtime_stream/data_generator.py\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from geopy.distance import geodesic\n",
    "import pytz\n",
    "\n",
    "from config import *\n",
    "\n",
    "# =====================================================\n",
    "# TIMEZONE CONFIGURATION\n",
    "# =====================================================\n",
    "IST = pytz.timezone(\"Asia/Kolkata\")\n",
    "\n",
    "# =====================================================\n",
    "# PATH CONFIGURATION\n",
    "# =====================================================\n",
    "BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "PROJECT_ROOT = os.path.dirname(BASE_DIR)\n",
    "\n",
    "OUTPUT_DIR = os.path.join(PROJECT_ROOT, \"phase5_dashboard\", \"data\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "CSV_PATH = os.path.join(OUTPUT_DIR, \"live_stream.csv\")\n",
    "if os.path.exists(CSV_PATH):\n",
    "    os.remove(CSV_PATH)\n",
    "\n",
    "# =====================================================\n",
    "# LOAD STATIC DATA\n",
    "# =====================================================\n",
    "vehicles = pd.read_csv(os.path.join(BASE_DIR, \"vehicle_master.csv\"))\n",
    "accidents = pd.read_csv(os.path.join(BASE_DIR, \"past_accidents.csv\"))\n",
    "\n",
    "# =====================================================\n",
    "# INITIALIZE VEHICLE POSITIONS\n",
    "# =====================================================\n",
    "vehicle_positions = {\n",
    "    v.vehicle_id: [START_LAT, START_LON]\n",
    "    for _, v in vehicles.iterrows()\n",
    "}\n",
    "\n",
    "# =====================================================\n",
    "# CONTROLLED RISK SIMULATION\n",
    "# These vehicles intentionally produce abnormal patterns\n",
    "# to test incident prediction and rerouting logic.\n",
    "# =====================================================\n",
    "HIGH_RISK_VEHICLES = random.sample(list(vehicle_positions.keys()), k=3)\n",
    "FORCED_REROUTE_VEHICLES = random.sample(list(vehicle_positions.keys()), k=2)\n",
    "\n",
    "# =====================================================\n",
    "# HELPER FUNCTIONS\n",
    "# =====================================================\n",
    "\n",
    "def move_gps(lat, lon):\n",
    "    \"\"\"Simulates small GPS movement.\"\"\"\n",
    "    return (\n",
    "        round(lat + random.uniform(-0.0005, 0.0005), 6),\n",
    "        round(lon + random.uniform(-0.0005, 0.0005), 6)\n",
    "    )\n",
    "\n",
    "def road_type():\n",
    "    \"\"\"Randomly selects road type with realistic distribution.\"\"\"\n",
    "    return random.choices(\n",
    "        [\"highway\", \"urban\", \"rural\"],\n",
    "        weights=[0.4, 0.4, 0.2]\n",
    "    )[0]\n",
    "\n",
    "def traffic_index():\n",
    "    \"\"\"Returns traffic congestion score between 0 and 1.\"\"\"\n",
    "    return round(random.uniform(0.1, 0.9), 2)\n",
    "\n",
    "def accident_risk(lat, lon):\n",
    "    \"\"\"Calculates historical accident risk based on proximity.\"\"\"\n",
    "    risk = 0.0\n",
    "    for _, row in accidents.iterrows():\n",
    "        distance_km = geodesic((lat, lon), (row.latitude, row.longitude)).km\n",
    "        if distance_km < 1:\n",
    "            risk += {\"High\": 0.6, \"Medium\": 0.3, \"Low\": 0.1}[row.severity]\n",
    "    return round(min(risk, 1.0), 2)\n",
    "\n",
    "def engine_health(vehicle_id):\n",
    "    \"\"\"Simulates engine condition and failure risk.\"\"\"\n",
    "    if vehicle_id in FORCED_REROUTE_VEHICLES:\n",
    "        return {\n",
    "            \"engine_temp\": 120,\n",
    "            \"fuel_level\": 5,\n",
    "            \"oil_pressure\": 15,\n",
    "            \"engine_risk\": 0.95\n",
    "        }\n",
    "\n",
    "    if vehicle_id in HIGH_RISK_VEHICLES or random.random() < 0.25:\n",
    "        return {\n",
    "            \"engine_temp\": random.randint(110, 120),\n",
    "            \"fuel_level\": random.randint(5, 15),\n",
    "            \"oil_pressure\": random.randint(15, 25),\n",
    "            \"engine_risk\": 0.8\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"engine_temp\": random.randint(70, 100),\n",
    "        \"fuel_level\": random.randint(20, 100),\n",
    "        \"oil_pressure\": random.randint(30, 80),\n",
    "        \"engine_risk\": 0.2\n",
    "    }\n",
    "\n",
    "def driver_behavior(vehicle_id):\n",
    "    \"\"\"Simulates driver driving patterns.\"\"\"\n",
    "    if vehicle_id in FORCED_REROUTE_VEHICLES:\n",
    "        return {\n",
    "            \"hard_brake\": 1,\n",
    "            \"rapid_acceleration\": 1,\n",
    "            \"idle_time\": 400,\n",
    "            \"driver_risk\": 0.9\n",
    "        }\n",
    "\n",
    "    if vehicle_id in HIGH_RISK_VEHICLES or random.random() < 0.25:\n",
    "        return {\n",
    "            \"hard_brake\": 1,\n",
    "            \"rapid_acceleration\": 1,\n",
    "            \"idle_time\": random.randint(250, 400),\n",
    "            \"driver_risk\": 0.7\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"hard_brake\": random.choice([0, 1]),\n",
    "        \"rapid_acceleration\": random.choice([0, 1]),\n",
    "        \"idle_time\": random.randint(0, 200),\n",
    "        \"driver_risk\": 0.2\n",
    "    }\n",
    "\n",
    "def weather_data(vehicle_id):\n",
    "    \"\"\"Simulates weather conditions and associated risk.\"\"\"\n",
    "    if vehicle_id in FORCED_REROUTE_VEHICLES:\n",
    "        weather = random.choice([\"rain\", \"fog\"])\n",
    "        return {\n",
    "            \"weather\": weather,\n",
    "            \"temperature\": random.randint(30, 40),\n",
    "            \"weather_risk\": 0.9\n",
    "        }\n",
    "\n",
    "    weather = (\n",
    "        random.choice([\"rain\", \"fog\"])\n",
    "        if vehicle_id in HIGH_RISK_VEHICLES and random.random() < 0.7\n",
    "        else random.choice(WEATHER_TYPES)\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"weather\": weather,\n",
    "        \"temperature\": random.randint(15, 40),\n",
    "        \"weather_risk\": WEATHER_RISK[weather]\n",
    "    }\n",
    "\n",
    "def nearby_accident_severity(vehicle_id):\n",
    "    \"\"\"Returns nearby accident severity level.\"\"\"\n",
    "    if vehicle_id in FORCED_REROUTE_VEHICLES:\n",
    "        return \"High\"\n",
    "\n",
    "    if vehicle_id in HIGH_RISK_VEHICLES and random.random() < 0.7:\n",
    "        return np.random.choice([\"Medium\", \"High\"], p=[0.3, 0.7])\n",
    "\n",
    "    return np.random.choice(\n",
    "        [\"None\", \"Low\", \"Medium\", \"High\"],\n",
    "        p=[0.5, 0.2, 0.2, 0.1]\n",
    "    )\n",
    "\n",
    "# =====================================================\n",
    "# EVENT GENERATOR\n",
    "# =====================================================\n",
    "\n",
    "def generate_event(vehicle):\n",
    "    \"\"\"Generates a single telemetry event for a vehicle.\"\"\"\n",
    "    lat, lon = vehicle_positions[vehicle.vehicle_id]\n",
    "    lat, lon = move_gps(lat, lon)\n",
    "    vehicle_positions[vehicle.vehicle_id] = [lat, lon]\n",
    "\n",
    "    road = road_type()\n",
    "    speed = random.randint(*SPEED_RANGES[road])\n",
    "\n",
    "    return {\n",
    "        \"event_id\": f\"{vehicle.vehicle_id}_{datetime.now().timestamp()}\",\n",
    "        \"timestamp\": datetime.now(IST).isoformat(),\n",
    "        \"vehicle_id\": vehicle.vehicle_id,\n",
    "        \"vehicle_type\": vehicle.vehicle_type,\n",
    "        \"capacity\": vehicle.capacity,\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": lon,\n",
    "        \"road_type\": road,\n",
    "        \"speed\": speed,\n",
    "        \"traffic_index\": traffic_index(),\n",
    "        **engine_health(vehicle.vehicle_id),\n",
    "        **driver_behavior(vehicle.vehicle_id),\n",
    "        **weather_data(vehicle.vehicle_id),\n",
    "        \"nearby_accident_severity\": nearby_accident_severity(vehicle.vehicle_id),\n",
    "        \"historical_accident_risk\": accident_risk(lat, lon)\n",
    "    }\n",
    "\n",
    "# =====================================================\n",
    "# STREAMING LOOP\n",
    "# =====================================================\n",
    "\n",
    "def stream_data():\n",
    "    \"\"\"Continuously streams real-time fleet data.\"\"\"\n",
    "    print(\"[INFO] Phase-1 real-time fleet data streaming started.\")\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            for _, vehicle in vehicles.iterrows():\n",
    "                event = generate_event(vehicle)\n",
    "                pd.DataFrame([event]).to_csv(\n",
    "                    CSV_PATH,\n",
    "                    mode=\"a\",\n",
    "                    header=not os.path.exists(CSV_PATH),\n",
    "                    index=False\n",
    "                )\n",
    "                print(f\"[DATA] Event generated for vehicle {vehicle.vehicle_id}\")\n",
    "                time.sleep(STREAM_INTERVAL)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n[INFO] Streaming stopped manually by user (Ctrl+C).\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Unexpected error occurred: {e}\")\n",
    "\n",
    "    finally:\n",
    "        print(\"[INFO] Phase-1 streaming service shut down gracefully.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    stream_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30884f5-5cdb-4fdb-bea1-8f73da833300",
   "metadata": {},
   "source": [
    "# **PHASE-2 â€” INCIDENT PREDICTION SYSTEM**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84126d02-2c7d-4c28-bc2c-02a5406d242e",
   "metadata": {},
   "source": [
    "\n",
    "This phase builds ML models to predict accident risk, vehicle breakdowns,\n",
    "route slowdowns, and potential disruptions using real-time features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30aa8351-8230-44b5-9e4f-7d8f4471a997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder created: phase2_incident_prediction\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "phase2_dir = \"phase2_incident_prediction\"\n",
    "\n",
    "os.makedirs(phase2_dir, exist_ok=True)\n",
    "\n",
    "print(\"Folder created:\", phase2_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25285c2c-ea7e-468d-841a-6a5391abf823",
   "metadata": {},
   "source": [
    "### **Incident Prediction Model Training**\n",
    "Trains multiple ML models including:\n",
    "- Random Forest\n",
    "- XGBoost\n",
    "- CatBoost\n",
    "- LSTM/GRU (sequence model)\n",
    "\n",
    "Evaluates models using precision, recall, F1-score, ROC-AUC,\n",
    "and false negative rate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9772bd1a-c03a-496e-a414-3e1e96170c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting phase2_incident_prediction/train_incident_models.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile phase2_incident_prediction/train_incident_models.py\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# =====================================================\n",
    "# PATH CONFIGURATION\n",
    "# =====================================================\n",
    "BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
    "MODEL_DIR = os.path.join(BASE_DIR, \"models\")\n",
    "\n",
    "MODEL_VERSION = datetime.now().strftime(\"v%Y%m%d_%H%M%S\")\n",
    "\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "# =====================================================\n",
    "# METRICS FUNCTION\n",
    "# =====================================================\n",
    "def compute_metrics(y_true, y_pred, y_prob):\n",
    "    fnr = ((y_true == 1) & (y_pred == 0)).sum() / max(1, (y_true == 1).sum())\n",
    "    return {\n",
    "        \"Precision\": round(precision_score(y_true, y_pred, zero_division=0), 3),\n",
    "        \"Recall\": round(recall_score(y_true, y_pred, zero_division=0), 3),\n",
    "        \"F1\": round(f1_score(y_true, y_pred, zero_division=0), 3),\n",
    "        \"ROC-AUC\": round(roc_auc_score(y_true, y_prob), 3),\n",
    "        \"False Negative Rate\": round(fnr, 3)\n",
    "    }\n",
    "\n",
    "# =====================================================\n",
    "# SYNTHETIC DATA GENERATION (SIMULATION)\n",
    "# =====================================================\n",
    "def generate_data(n=10000):\n",
    "    df = pd.DataFrame({\n",
    "        \"speed\": np.random.randint(10, 100, n),\n",
    "        \"traffic_index\": np.random.uniform(0.1, 1.0, n),\n",
    "        \"engine_temp\": np.random.randint(70, 120, n),\n",
    "        \"fuel_level\": np.random.randint(5, 100, n),\n",
    "        \"oil_pressure\": np.random.randint(15, 80, n),\n",
    "        \"hard_brake\": np.random.choice([0, 1], n),\n",
    "        \"rapid_acceleration\": np.random.choice([0, 1], n),\n",
    "        \"idle_time\": np.random.randint(0, 400, n),\n",
    "        \"road_type\": np.random.choice([\"highway\", \"urban\", \"rural\"], n),\n",
    "        \"weather\": np.random.choice([\"clear\", \"rain\", \"fog\"], n),\n",
    "        \"temperature\": np.random.randint(10, 45, n),\n",
    "        \"nearby_accident_severity\": np.random.choice(\n",
    "            [\"None\", \"Low\", \"Medium\", \"High\"], n\n",
    "        )\n",
    "    })\n",
    "\n",
    "    df[\"accident_risk\"] = (\n",
    "        (df[\"traffic_index\"] > 0.7) &\n",
    "        (df[\"weather\"].isin([\"rain\", \"fog\"])) &\n",
    "        (df[\"hard_brake\"] == 1)\n",
    "    ).astype(int)\n",
    "\n",
    "    df[\"breakdown_risk\"] = (\n",
    "        (df[\"engine_temp\"] > 105) |\n",
    "        (df[\"fuel_level\"] < 15)\n",
    "    ).astype(int)\n",
    "\n",
    "    df[\"slowdown_risk\"] = (\n",
    "        (df[\"speed\"] < 25) &\n",
    "        (df[\"traffic_index\"] > 0.6)\n",
    "    ).astype(int)\n",
    "\n",
    "    df[\"route_blockage_risk\"] = (\n",
    "        (df[\"traffic_index\"] > 0.85) &\n",
    "        (df[\"nearby_accident_severity\"] == \"High\")\n",
    "    ).astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "print(\"[INFO] Generating training data...\")\n",
    "df = generate_data()\n",
    "df.to_csv(os.path.join(DATA_DIR, \"incident_training_data.csv\"), index=False)\n",
    "\n",
    "# =====================================================\n",
    "# PREPROCESSING\n",
    "# =====================================================\n",
    "targets = [\n",
    "    \"accident_risk\",\n",
    "    \"breakdown_risk\",\n",
    "    \"slowdown_risk\",\n",
    "    \"route_blockage_risk\"\n",
    "]\n",
    "\n",
    "X = df.drop(columns=targets)\n",
    "y = df[targets]\n",
    "\n",
    "categorical_cols = [\"road_type\", \"weather\", \"nearby_accident_severity\"]\n",
    "encoders = {}\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col])\n",
    "    encoders[col] = le\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "joblib.dump(encoders, os.path.join(MODEL_DIR, f\"encoders_{MODEL_VERSION}.pkl\"))\n",
    "joblib.dump(scaler, os.path.join(MODEL_DIR, f\"scaler_{MODEL_VERSION}.pkl\"))\n",
    "\n",
    "# =====================================================\n",
    "# TRAIN / TEST SPLIT\n",
    "# =====================================================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# =====================================================\n",
    "# TREE-BASED MODELS\n",
    "# =====================================================\n",
    "tree_models = {}\n",
    "\n",
    "for risk in targets:\n",
    "    print(f\"[INFO] Training tree-based models for target: {risk}\")\n",
    "\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    xgb = XGBClassifier(\n",
    "        eval_metric=\"logloss\",\n",
    "        scale_pos_weight=(y_train[risk] == 0).sum() / max(1, (y_train[risk] == 1).sum())\n",
    "    )\n",
    "\n",
    "    cat = CatBoostClassifier(iterations=150, verbose=0)\n",
    "\n",
    "    rf.fit(X_train, y_train[risk])\n",
    "    xgb.fit(X_train, y_train[risk])\n",
    "    cat.fit(X_train, y_train[risk])\n",
    "\n",
    "    prob = rf.predict_proba(X_test)[:, 1]\n",
    "    pred = (prob > 0.5).astype(int)\n",
    "\n",
    "    print(\"[METRICS]\", compute_metrics(y_test[risk], pred, prob))\n",
    "\n",
    "    tree_models[risk] = {\n",
    "        \"rf\": rf,\n",
    "        \"xgb\": xgb,\n",
    "        \"cat\": cat\n",
    "    }\n",
    "\n",
    "joblib.dump(\n",
    "    tree_models,\n",
    "    os.path.join(MODEL_DIR, f\"tree_models_{MODEL_VERSION}.pkl\")\n",
    ")\n",
    "\n",
    "# =====================================================\n",
    "# LSTM SEQUENCE MODELS (TEMPORAL)\n",
    "# =====================================================\n",
    "SEQ_LEN = 5\n",
    "N_FEATURES = X_scaled.shape[1]\n",
    "\n",
    "def build_sequences(X, y):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - SEQ_LEN):\n",
    "        X_seq.append(X[i:i + SEQ_LEN])\n",
    "        y_seq.append(y[i + SEQ_LEN])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "lstm_models = {}\n",
    "\n",
    "for risk in targets:\n",
    "    print(f\"[INFO] Training LSTM model for target: {risk}\")\n",
    "\n",
    "    X_seq, y_seq = build_sequences(X_scaled, y[risk].values)\n",
    "\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "        X_seq, y_seq, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    class_weights = compute_class_weight(\n",
    "        class_weight=\"balanced\",\n",
    "        classes=np.unique(y_tr),\n",
    "        y=y_tr\n",
    "    )\n",
    "    class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "    model = Sequential([\n",
    "        Input(shape=(SEQ_LEN, N_FEATURES)),\n",
    "        LSTM(64, return_sequences=True),\n",
    "        Dropout(0.3),\n",
    "        LSTM(32),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"Recall\"]\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_tr,\n",
    "        y_tr,\n",
    "        epochs=15,\n",
    "        batch_size=64,\n",
    "        validation_split=0.2,\n",
    "        class_weight=class_weight_dict,\n",
    "        callbacks=[EarlyStopping(patience=4, restore_best_weights=True)],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    y_prob = model.predict(X_te).ravel()\n",
    "    y_pred = (y_prob > 0.4).astype(int)  # safety-oriented threshold\n",
    "\n",
    "    print(\"[METRICS]\", compute_metrics(y_te, y_pred, y_prob))\n",
    "\n",
    "    lstm_models[risk] = model\n",
    "\n",
    "joblib.dump(\n",
    "    lstm_models,\n",
    "    os.path.join(MODEL_DIR, f\"lstm_models_{MODEL_VERSION}.pkl\")\n",
    ")\n",
    "\n",
    "print(\"[SUCCESS] Phase-2 model training completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bf7cae-5408-4158-8d19-077d06823413",
   "metadata": {},
   "source": [
    "### **Automated Model Retraining**\n",
    "Implements scheduled retraining logic to ensure models remain\n",
    "up-to-date with evolving traffic and fleet behavior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f92c3f02-9506-4e21-a2f6-4198ac72925d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing phase2_incident_prediction/auto_retrain.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile phase2_incident_prediction/auto_retrain.py\n",
    "import pytz\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "IST = pytz.timezone(\"Asia/Kolkata\")\n",
    "\n",
    "print(\"[INFO] Automated retraining job triggered\")\n",
    "print(\"[INFO] Timestamp:\", datetime.now(IST).isoformat())\n",
    "\n",
    "subprocess.run(\n",
    "    [\"python\", \"phase2_incident_prediction/train_incident_models.py\"],\n",
    "    check=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5d3712-9202-4a9d-b659-9f16629e2ba6",
   "metadata": {},
   "source": [
    "### **Data Drift Monitoring**\n",
    "Detects distribution shifts in GPS patterns, incident frequency,\n",
    "and traffic behavior to trigger retraining when necessary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae4b1d3f-c0dc-4604-808d-303b6a0dca76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing phase2_incident_prediction/drift_monitor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile phase2_incident_prediction/drift_monitor.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "BASELINE = \"phase2_incident_prediction/data/incident_training_data.csv\"\n",
    "LIVE = \"phase5_dashboard/data/live_stream.csv\"\n",
    "\n",
    "DRIFT_THRESHOLD = 0.3\n",
    "\n",
    "baseline = pd.read_csv(BASELINE)\n",
    "live = pd.read_csv(LIVE).tail(500)\n",
    "\n",
    "features = [\n",
    "    \"speed\",\n",
    "    \"traffic_index\",\n",
    "    \"engine_temp\",\n",
    "    \"fuel_level\",\n",
    "    \"idle_time\"\n",
    "]\n",
    "\n",
    "print(\"[INFO] Drift monitoring report\")\n",
    "\n",
    "for f in features:\n",
    "    base_mean = baseline[f].mean()\n",
    "    live_mean = live[f].mean()\n",
    "\n",
    "    drift_score = abs(live_mean - base_mean) / (base_mean + 1e-6)\n",
    "\n",
    "    if drift_score > DRIFT_THRESHOLD:\n",
    "        print(f\"[WARNING] Drift detected in {f}: score={drift_score:.2f}\")\n",
    "    else:\n",
    "        print(f\"[OK] {f} stable (score={drift_score:.2f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958f3f05-6d74-4e9b-985b-6074ca21cf88",
   "metadata": {},
   "source": [
    "### **Real-Time Incident Inference**\n",
    "Consumes live data streams and produces real-time incident\n",
    "probability predictions used by routing and optimization engines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9d3b98c-5263-4e30-8b64-acbda9d96568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting phase1_realtime_stream/phase2_live_inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile phase1_realtime_stream/phase2_live_inference.py\n",
    "import os\n",
    "import time\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "from collections import deque\n",
    "\n",
    "# =====================================================\n",
    "# PATH CONFIGURATION\n",
    "# =====================================================\n",
    "BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "\n",
    "STREAM_FILE = os.path.join(\n",
    "    BASE_DIR, \"..\", \"phase5_dashboard\", \"data\", \"live_stream.csv\"\n",
    ")\n",
    "\n",
    "OUTPUT_FILE = os.path.join(\n",
    "    BASE_DIR, \"..\", \"phase5_dashboard\", \"data\", \"live_predictions.csv\"\n",
    ")\n",
    "\n",
    "MODEL_DIR = os.path.join(\n",
    "    BASE_DIR, \"..\", \"phase2_incident_prediction\", \"models\"\n",
    ")\n",
    "\n",
    "os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)\n",
    "\n",
    "# =====================================================\n",
    "# MODEL LOADING\n",
    "# =====================================================\n",
    "def load_latest(prefix: str):\n",
    "    files = [f for f in os.listdir(MODEL_DIR) if f.startswith(prefix)]\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No models found for prefix: {prefix}\")\n",
    "    latest = sorted(files)[-1]\n",
    "    return joblib.load(os.path.join(MODEL_DIR, latest))\n",
    "\n",
    "print(\"[INFO] Loading trained models...\")\n",
    "\n",
    "tree_models = load_latest(\"tree_models\")\n",
    "lstm_models = load_latest(\"lstm_models\")\n",
    "encoders = load_latest(\"encoders\")\n",
    "scaler = load_latest(\"scaler\")\n",
    "\n",
    "print(\"[SUCCESS] Models loaded successfully\")\n",
    "\n",
    "# =====================================================\n",
    "# FEATURE DEFINITIONS\n",
    "# =====================================================\n",
    "categorical_cols = [\n",
    "    \"road_type\",\n",
    "    \"weather\",\n",
    "    \"nearby_accident_severity\"\n",
    "]\n",
    "\n",
    "feature_cols = [\n",
    "    \"speed\", \"traffic_index\", \"engine_temp\", \"fuel_level\", \"oil_pressure\",\n",
    "    \"hard_brake\", \"rapid_acceleration\", \"idle_time\",\n",
    "    \"road_type\", \"weather\", \"temperature\",\n",
    "    \"nearby_accident_severity\"\n",
    "]\n",
    "\n",
    "risk_types = list(tree_models.keys())\n",
    "\n",
    "# =====================================================\n",
    "# LSTM SEQUENCE CONFIGURATION\n",
    "# =====================================================\n",
    "SEQ_LEN = 5\n",
    "vehicle_sequences = {}   # vehicle_id -> deque\n",
    "\n",
    "# =====================================================\n",
    "# PREPROCESSING FUNCTION\n",
    "# =====================================================\n",
    "def preprocess(df: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Ensures schema consistency, encodes categoricals,\n",
    "    and applies standard scaling.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Fill missing columns\n",
    "    for col in feature_cols:\n",
    "        if col not in df.columns:\n",
    "            df[col] = \"None\" if col in categorical_cols else 0\n",
    "\n",
    "    # Encode categoricals safely\n",
    "    for col in categorical_cols:\n",
    "        df[col] = df[col].fillna(\"None\")\n",
    "        known = set(encoders[col].classes_)\n",
    "        df[col] = df[col].apply(lambda x: x if x in known else \"None\")\n",
    "        df[col] = encoders[col].transform(df[col])\n",
    "\n",
    "    return scaler.transform(df[feature_cols])\n",
    "\n",
    "# =====================================================\n",
    "# STREAMING INFERENCE LOOP\n",
    "# =====================================================\n",
    "print(\"[INFO] Phase-2 Live Inference Started\")\n",
    "\n",
    "last_row = 0\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        if not os.path.exists(STREAM_FILE):\n",
    "            time.sleep(2)\n",
    "            continue\n",
    "\n",
    "        df = pd.read_csv(STREAM_FILE)\n",
    "\n",
    "        if len(df) <= last_row:\n",
    "            time.sleep(2)\n",
    "            continue\n",
    "\n",
    "        new_data = df.iloc[last_row:].reset_index(drop=True)\n",
    "        last_row = len(df)\n",
    "\n",
    "        X_live = preprocess(new_data)\n",
    "\n",
    "        output = {\n",
    "            \"timestamp\": new_data[\"timestamp\"],\n",
    "            \"vehicle_id\": new_data[\"vehicle_id\"]\n",
    "        }\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # LSTM SEQUENCE PREDICTIONS\n",
    "        # -------------------------------------------------\n",
    "        lstm_preds = {}\n",
    "\n",
    "        for i, vid in enumerate(new_data[\"vehicle_id\"]):\n",
    "            vehicle_sequences.setdefault(vid, deque(maxlen=SEQ_LEN))\n",
    "            vehicle_sequences[vid].append(X_live[i])\n",
    "\n",
    "            if len(vehicle_sequences[vid]) == SEQ_LEN:\n",
    "                seq = np.array(vehicle_sequences[vid]).reshape(1, SEQ_LEN, -1)\n",
    "                lstm_preds[vid] = {\n",
    "                    risk: lstm_models[risk].predict(seq, verbose=0)[0][0]\n",
    "                    for risk in risk_types\n",
    "                }\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # TREE + LSTM ENSEMBLE\n",
    "        # -------------------------------------------------\n",
    "        for risk in risk_types:\n",
    "            rf = tree_models[risk][\"rf\"]\n",
    "            xgb = tree_models[risk][\"xgb\"]\n",
    "            cat = tree_models[risk][\"cat\"]\n",
    "\n",
    "            tree_prob = (\n",
    "                0.4 * rf.predict_proba(X_live)[:, 1] +\n",
    "                0.4 * xgb.predict_proba(X_live)[:, 1] +\n",
    "                0.2 * cat.predict_proba(X_live)[:, 1]\n",
    "            )\n",
    "\n",
    "            final_prob = []\n",
    "\n",
    "            for i, vid in enumerate(new_data[\"vehicle_id\"]):\n",
    "                lstm_p = lstm_preds.get(vid, {}).get(risk, tree_prob[i])\n",
    "                final_prob.append(0.7 * tree_prob[i] + 0.3 * lstm_p)\n",
    "\n",
    "            p = np.array(final_prob)\n",
    "\n",
    "            # -------------------------------------------------\n",
    "            # SAFETY ESCALATION LOGIC\n",
    "            # -------------------------------------------------\n",
    "            escalation = (\n",
    "                (new_data[\"traffic_index\"] > 0.85).astype(int) +\n",
    "                (new_data[\"engine_temp\"] > 105).astype(int) +\n",
    "                (new_data[\"weather\"].isin([\"rain\", \"fog\"])).astype(int) +\n",
    "                (new_data[\"nearby_accident_severity\"] == \"High\").astype(int)\n",
    "            )\n",
    "\n",
    "            p = np.where(escalation >= 2, np.maximum(p, 0.75), p)\n",
    "\n",
    "            output[risk] = np.round(p, 3)\n",
    "            output[f\"{risk}_confidence\"] = np.round(p, 3)\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # SAVE OUTPUT\n",
    "        # -------------------------------------------------\n",
    "        pd.DataFrame(output).to_csv(\n",
    "            OUTPUT_FILE,\n",
    "            mode=\"a\",\n",
    "            header=not os.path.exists(OUTPUT_FILE),\n",
    "            index=False\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"[INFO] {len(new_data)} predictions generated @ \"\n",
    "            f\"{datetime.now().strftime('%H:%M:%S')}\"\n",
    "        )\n",
    "\n",
    "        time.sleep(2)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n[SHUTDOWN] Live inference stopped safely by user\")\n",
    "        break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"[ERROR] Inference failure:\", str(e))\n",
    "        time.sleep(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09b5c92-7c4f-489f-b47e-6fdc7b714a52",
   "metadata": {},
   "source": [
    "# **PHASE-3: Fleet Scheduling Optimization (Genetic Algorithm)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a85fee-5fc1-4459-ae12-0281764e2cb7",
   "metadata": {},
   "source": [
    "This phase optimizes vehicle-to-task assignment while minimizing\n",
    "fuel cost, delay, and idle time under operational constraints.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd275b7b-69cf-4df1-8bd6-70b17dde343c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder created: phase3_fleet_optimization\n"
     ]
    }
   ],
   "source": [
    "\n",
    "phase3_dir = \"phase3_fleet_optimization\"\n",
    "\n",
    "os.makedirs(phase3_dir, exist_ok=True)\n",
    "\n",
    "print(\"Folder created:\", phase3_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a2e323-0d5b-4685-8017-0a0db9a4a498",
   "metadata": {},
   "source": [
    "### **Fleet Optimization Engine**\n",
    "Implements a Genetic Algorithm / OR-Tools based Vehicle Routing Problem (VRP)\n",
    "solver that accounts for:\n",
    "- Vehicle capacity\n",
    "- Driver shift limits\n",
    "- Traffic congestion\n",
    "- Delivery time windows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a480010d-1e86-47e8-a4bc-bdcbbf3eb228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing phase3_fleet_optimization/fleet_optimizer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile phase3_fleet_optimization/fleet_optimizer.py\n",
    "\"\"\"\n",
    "\n",
    "This module assigns delivery tasks to vehicles using a Genetic Algorithm\n",
    "while incorporating real-time risk predictions and GPS data. Vehicles\n",
    "with high predicted risk are flagged for rerouting.\n",
    "\n",
    "Designed for demo, dashboard integration, and enterprise-style ML pipelines.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Timezone Configuration\n",
    "# -------------------------------------------------------------------\n",
    "IST = pytz.timezone(\"Asia/Kolkata\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Path Configuration\n",
    "# -------------------------------------------------------------------\n",
    "BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
    "\n",
    "VEHICLE_MASTER = os.path.join(\n",
    "    BASE_DIR, \"phase1_realtime_stream\", \"vehicle_master.csv\"\n",
    ")\n",
    "\n",
    "LIVE_STREAM = os.path.join(\n",
    "    BASE_DIR, \"phase5_dashboard\", \"data\", \"live_stream.csv\"\n",
    ")\n",
    "\n",
    "PREDICTIONS_FILE = os.path.join(\n",
    "    BASE_DIR, \"phase5_dashboard\", \"data\", \"live_predictions.csv\"\n",
    ")\n",
    "\n",
    "OUTPUT_DIR = os.path.join(\n",
    "    BASE_DIR, \"phase5_dashboard\", \"data\"\n",
    ")\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# System Parameters\n",
    "# -------------------------------------------------------------------\n",
    "RUN_INTERVAL = 30  # seconds\n",
    "\n",
    "RISK_THRESHOLD = 0.65\n",
    "CRITICAL_THRESHOLD = 0.85\n",
    "\n",
    "DEFAULT_DEST = {\"lat\": 17.4500, \"lon\": 78.5000}\n",
    "\n",
    "# Demo mode forces rerouting for dashboard visibility\n",
    "DEMO_MODE = True\n",
    "DEMO_REROUTE_COUNT = 10\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Delivery Task Definitions (Synthetic)\n",
    "# -------------------------------------------------------------------\n",
    "TASKS = [\n",
    "    {\"task_id\": 0, \"distance\": 40, \"demand\": 30, \"traffic\": 1.2, \"deadline\": 5},\n",
    "    {\"task_id\": 1, \"distance\": 60, \"demand\": 50, \"traffic\": 1.5, \"deadline\": 7},\n",
    "    {\"task_id\": 2, \"distance\": 30, \"demand\": 20, \"traffic\": 1.1, \"deadline\": 4},\n",
    "    {\"task_id\": 3, \"distance\": 80, \"demand\": 40, \"traffic\": 1.6, \"deadline\": 8},\n",
    "]\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Genetic Algorithm Helpers\n",
    "# -------------------------------------------------------------------\n",
    "def create_chromosome(num_tasks, num_vehicles):\n",
    "    return [random.randint(0, num_vehicles - 1) for _ in range(num_tasks)]\n",
    "\n",
    "def crossover(parent1, parent2):\n",
    "    point = random.randint(1, len(parent1) - 1)\n",
    "    return parent1[:point] + parent2[point:]\n",
    "\n",
    "def mutate(chromosome, num_vehicles, rate=0.15):\n",
    "    for i in range(len(chromosome)):\n",
    "        if random.random() < rate:\n",
    "            chromosome[i] = random.randint(0, num_vehicles - 1)\n",
    "    return chromosome\n",
    "\n",
    "def tournament_selection(population, fitness_fn, k=3):\n",
    "    return min(random.sample(population, k), key=fitness_fn)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Core Optimization Logic\n",
    "# -------------------------------------------------------------------\n",
    "def run_fleet_optimization():\n",
    "    \"\"\"\n",
    "    Executes one optimization cycle:\n",
    "    - Loads vehicles and live GPS data\n",
    "    - Integrates ML risk predictions\n",
    "    - Runs GA-based task assignment\n",
    "    - Flags vehicles requiring rerouting\n",
    "    - Saves optimized fleet schedule\n",
    "    \"\"\"\n",
    "\n",
    "    # Load vehicle master\n",
    "    vehicles_df = pd.read_csv(VEHICLE_MASTER)\n",
    "\n",
    "    if \"shift_hours\" not in vehicles_df.columns:\n",
    "        vehicles_df[\"shift_hours\"] = 8\n",
    "\n",
    "    vehicles_df[\"risk_score\"] = 0.0\n",
    "    vehicles_df[\"reroute_required\"] = False\n",
    "    vehicles_df[\"reroute_reason\"] = \"\"\n",
    "\n",
    "    # -------------------------------------------------------------------\n",
    "    # Live GPS Integration\n",
    "    # -------------------------------------------------------------------\n",
    "    if os.path.exists(LIVE_STREAM):\n",
    "        live_df = pd.read_csv(LIVE_STREAM)\n",
    "        latest = live_df.groupby(\"vehicle_id\").last().reset_index()\n",
    "\n",
    "        vehicles_df = vehicles_df.merge(\n",
    "            latest[[\"vehicle_id\", \"latitude\", \"longitude\"]],\n",
    "            on=\"vehicle_id\",\n",
    "            how=\"left\"\n",
    "        )\n",
    "    else:\n",
    "        vehicles_df[\"latitude\"] = 17.3850\n",
    "        vehicles_df[\"longitude\"] = 78.4867\n",
    "\n",
    "    # -------------------------------------------------------------------\n",
    "    # Phase-2 Risk Prediction Integration\n",
    "    # -------------------------------------------------------------------\n",
    "    if os.path.exists(PREDICTIONS_FILE):\n",
    "        pred_df = pd.read_csv(PREDICTIONS_FILE)\n",
    "        latest_pred = pred_df.groupby(\"vehicle_id\").last().reset_index()\n",
    "\n",
    "        vehicles_df = (\n",
    "            vehicles_df.merge(latest_pred, on=\"vehicle_id\", how=\"left\")\n",
    "            .fillna(0)\n",
    "        )\n",
    "\n",
    "        for idx, row in vehicles_df.iterrows():\n",
    "            accident = row.get(\"accident_risk\", 0)\n",
    "            breakdown = row.get(\"breakdown_risk\", 0)\n",
    "            blockage = row.get(\"route_blockage_risk\", 0)\n",
    "\n",
    "            risk_score = round(\n",
    "                0.5 * accident + 0.3 * breakdown + 0.2 * blockage, 3\n",
    "            )\n",
    "\n",
    "            vehicles_df.at[idx, \"risk_score\"] = risk_score\n",
    "\n",
    "            reasons = []\n",
    "            if risk_score >= RISK_THRESHOLD:\n",
    "                reasons.append(\"High composite risk\")\n",
    "            if accident >= CRITICAL_THRESHOLD:\n",
    "                reasons.append(\"Critical accident risk\")\n",
    "            if breakdown >= CRITICAL_THRESHOLD:\n",
    "                reasons.append(\"Critical breakdown risk\")\n",
    "            if blockage >= CRITICAL_THRESHOLD:\n",
    "                reasons.append(\"Critical route blockage\")\n",
    "\n",
    "            if reasons:\n",
    "                vehicles_df.at[idx, \"reroute_required\"] = True\n",
    "                vehicles_df.at[idx, \"reroute_reason\"] = \"; \".join(reasons)\n",
    "\n",
    "    # -------------------------------------------------------------------\n",
    "    # Demo Override (for visualization)\n",
    "    # -------------------------------------------------------------------\n",
    "    if DEMO_MODE:\n",
    "        demo_targets = vehicles_df.sort_values(\n",
    "            \"risk_score\", ascending=False\n",
    "        ).head(DEMO_REROUTE_COUNT)\n",
    "\n",
    "        for i, idx in enumerate(demo_targets.index):\n",
    "            if i < len(demo_targets) * 0.5:\n",
    "                vehicles_df.at[idx, \"risk_score\"] = 0.55\n",
    "                vehicles_df.at[idx, \"reroute_required\"] = False\n",
    "                vehicles_df.at[idx, \"reroute_reason\"] = \"Demo: Moderate risk\"\n",
    "            else:\n",
    "                vehicles_df.at[idx, \"risk_score\"] = 0.88\n",
    "                vehicles_df.at[idx, \"reroute_required\"] = True\n",
    "                vehicles_df.at[idx, \"reroute_reason\"] = \"Demo: Critical risk\"\n",
    "\n",
    "    # Destination\n",
    "    vehicles_df[\"dest_lat\"] = DEFAULT_DEST[\"lat\"]\n",
    "    vehicles_df[\"dest_lon\"] = DEFAULT_DEST[\"lon\"]\n",
    "\n",
    "    vehicles = vehicles_df.to_dict(\"records\")\n",
    "\n",
    "    # -------------------------------------------------------------------\n",
    "    # Fitness Function\n",
    "    # -------------------------------------------------------------------\n",
    "    def fitness(chromosome):\n",
    "        cost = 0\n",
    "        load = {v[\"vehicle_id\"]: 0 for v in vehicles}\n",
    "\n",
    "        for i, vehicle_idx in enumerate(chromosome):\n",
    "            task = TASKS[i]\n",
    "            vehicle = vehicles[vehicle_idx]\n",
    "\n",
    "            load[vehicle[\"vehicle_id\"]] += task[\"demand\"]\n",
    "            cost += task[\"distance\"] * 0.05\n",
    "            cost += vehicle[\"risk_score\"] * 120\n",
    "\n",
    "        cost += np.var(list(load.values())) * 2\n",
    "        return cost\n",
    "\n",
    "    # -------------------------------------------------------------------\n",
    "    # Run Genetic Algorithm\n",
    "    # -------------------------------------------------------------------\n",
    "    population = [\n",
    "        create_chromosome(len(TASKS), len(vehicles))\n",
    "        for _ in range(40)\n",
    "    ]\n",
    "\n",
    "    for _ in range(60):\n",
    "        population = [\n",
    "            mutate(\n",
    "                crossover(\n",
    "                    tournament_selection(population, fitness),\n",
    "                    tournament_selection(population, fitness)\n",
    "                ),\n",
    "                len(vehicles)\n",
    "            )\n",
    "            for _ in range(len(population))\n",
    "        ]\n",
    "\n",
    "    best_solution = min(population, key=fitness)\n",
    "\n",
    "    schedule = pd.DataFrame({\n",
    "        \"task_id\": [t[\"task_id\"] for t in TASKS],\n",
    "        \"vehicle_id\": [vehicles[i][\"vehicle_id\"] for i in best_solution],\n",
    "        \"risk_score\": [vehicles[i][\"risk_score\"] for i in best_solution],\n",
    "        \"reroute_required\": [vehicles[i][\"reroute_required\"] for i in best_solution],\n",
    "        \"reroute_reason\": [vehicles[i][\"reroute_reason\"] for i in best_solution],\n",
    "        \"latitude\": [vehicles[i][\"latitude\"] for i in best_solution],\n",
    "        \"longitude\": [vehicles[i][\"longitude\"] for i in best_solution],\n",
    "        \"dest_lat\": [vehicles[i][\"dest_lat\"] for i in best_solution],\n",
    "        \"dest_lon\": [vehicles[i][\"dest_lon\"] for i in best_solution],\n",
    "        \"timestamp\": datetime.now(IST).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    })\n",
    "\n",
    "    schedule.to_csv(\n",
    "        os.path.join(OUTPUT_DIR, \"fleet_schedule.csv\"),\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "    flagged = schedule[\"reroute_required\"].sum()\n",
    "    if flagged:\n",
    "        print(f\"[INFO] {flagged} vehicle(s) flagged for rerouting.\")\n",
    "    else:\n",
    "        print(\"[INFO] Fleet operating within safe risk thresholds.\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Continuous Execution Loop\n",
    "# -------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"[SYSTEM] Phase-3 Fleet Scheduling Optimization started.\")\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            run_fleet_optimization()\n",
    "            time.sleep(RUN_INTERVAL)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n[SYSTEM] Phase-3 optimization stopped by user.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69649a47-1f5a-4b3b-bd31-47d42d5fac15",
   "metadata": {},
   "source": [
    "# **PHASE-4 â€” DYNAMIC REROUTING SYSTEM**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6175f8f8-d364-477f-95a0-a43ff114c483",
   "metadata": {},
   "source": [
    "This phase dynamically reroutes vehicles when high-risk incidents\n",
    "are predicted to ensure safety and on-time delivery.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a717e705-ebf7-401f-9640-fd66752bae0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder created: phase4_dynamic_rerouting\n"
     ]
    }
   ],
   "source": [
    "phase4_dir = \"phase4_dynamic_rerouting\"\n",
    "\n",
    "os.makedirs(phase4_dir, exist_ok=True)\n",
    "\n",
    "print(\"Folder created:\", phase4_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3eec69-2b16-4541-ad25-f5a6376097e7",
   "metadata": {},
   "source": [
    "### **Intelligent Route Recalculation**\n",
    "Uses OSRM / OpenRouteService APIs to:\n",
    "- Identify safer alternative routes\n",
    "- Update ETA dynamically\n",
    "- Log rerouting events for monitoring\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b9198fc-36c3-446b-afaf-e5388053a334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing phase4_dynamic_rerouting/dynamic_rerouting.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile phase4_dynamic_rerouting/dynamic_rerouting.py\n",
    "\"\"\"\n",
    "This module performs dynamic rerouting strictly based on Phase-3 fleet\n",
    "optimization output. Vehicles flagged for rerouting are assigned a new\n",
    "destination, ETA is recalculated, and reroute events are logged.\n",
    "\n",
    "Designed for real-time dashboards and intelligent transportation systems.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from geopy.distance import geodesic\n",
    "import folium\n",
    "import pytz\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Timezone Configuration\n",
    "# -------------------------------------------------------------------\n",
    "IST = pytz.timezone(\"Asia/Kolkata\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Path Configuration\n",
    "# -------------------------------------------------------------------\n",
    "BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
    "\n",
    "FLEET_FILE = os.path.join(\n",
    "    BASE_DIR, \"phase5_dashboard\", \"data\", \"fleet_schedule.csv\"\n",
    ")\n",
    "\n",
    "OUTPUT_DIR = os.path.join(\n",
    "    BASE_DIR, \"phase5_dashboard\", \"data\"\n",
    ")\n",
    "\n",
    "REROUTE_LOG = os.path.join(\n",
    "    OUTPUT_DIR, \"rerouting_logs.csv\"\n",
    ")\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# System Parameters\n",
    "# -------------------------------------------------------------------\n",
    "UPDATE_INTERVAL = 30          # seconds\n",
    "MAX_DEST_SHIFT = 0.004        # realistic destination deviation\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Helper Functions\n",
    "# -------------------------------------------------------------------\n",
    "def estimate_eta(lat1, lon1, lat2, lon2, speed=40):\n",
    "    \"\"\"\n",
    "    Estimate ETA and distance between two coordinates.\n",
    "\n",
    "    Returns:\n",
    "        eta_minutes (float), distance_km (float)\n",
    "    \"\"\"\n",
    "    distance_km = geodesic((lat1, lon1), (lat2, lon2)).km\n",
    "    eta_minutes = (distance_km / speed) * 60\n",
    "    return round(eta_minutes, 1), round(distance_km, 2)\n",
    "\n",
    "def generate_map(lat1, lon1, lat2, lon2, vehicle_id):\n",
    "    \"\"\"\n",
    "    Generate an HTML map showing rerouted vehicle path.\n",
    "    \"\"\"\n",
    "    fmap = folium.Map(location=[lat1, lon1], zoom_start=13)\n",
    "\n",
    "    folium.Marker(\n",
    "        [lat1, lon1],\n",
    "        icon=folium.Icon(color=\"red\", icon=\"truck\", prefix=\"fa\"),\n",
    "        tooltip=f\"Vehicle {vehicle_id} (Rerouted)\"\n",
    "    ).add_to(fmap)\n",
    "\n",
    "    folium.Marker(\n",
    "        [lat2, lon2],\n",
    "        icon=folium.Icon(color=\"green\"),\n",
    "        tooltip=\"New Destination\"\n",
    "    ).add_to(fmap)\n",
    "\n",
    "    folium.PolyLine(\n",
    "        [[lat1, lon1], [lat2, lon2]],\n",
    "        weight=3\n",
    "    ).add_to(fmap)\n",
    "\n",
    "    map_path = os.path.join(OUTPUT_DIR, f\"reroute_{vehicle_id}.html\")\n",
    "    fmap.save(map_path)\n",
    "    return map_path\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Core Rerouting Logic\n",
    "# -------------------------------------------------------------------\n",
    "def run_dynamic_rerouting():\n",
    "    \"\"\"\n",
    "    Executes one rerouting cycle:\n",
    "    - Reads Phase-3 fleet schedule\n",
    "    - Identifies vehicles flagged for rerouting\n",
    "    - Computes alternate routes\n",
    "    - Logs reroute events\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(FLEET_FILE):\n",
    "        print(\"[INFO] Phase-3 output not available. Waiting...\")\n",
    "        return\n",
    "\n",
    "    fleet_df = pd.read_csv(FLEET_FILE)\n",
    "\n",
    "    if \"rerouted_at\" not in fleet_df.columns:\n",
    "        fleet_df[\"rerouted_at\"] = \"\"\n",
    "\n",
    "    reroute_count = 0\n",
    "\n",
    "    for idx, row in fleet_df.iterrows():\n",
    "\n",
    "        # Process only vehicles flagged by Phase-3\n",
    "        if not row.get(\"reroute_required\", False):\n",
    "            continue\n",
    "\n",
    "        # Prevent repeated rerouting\n",
    "        if str(row[\"rerouted_at\"]).strip():\n",
    "            continue\n",
    "\n",
    "        # Generate alternate destination\n",
    "        new_lat = row[\"dest_lat\"] + random.uniform(-MAX_DEST_SHIFT, MAX_DEST_SHIFT)\n",
    "        new_lon = row[\"dest_lon\"] + random.uniform(-MAX_DEST_SHIFT, MAX_DEST_SHIFT)\n",
    "\n",
    "        eta, distance = estimate_eta(\n",
    "            row[\"latitude\"], row[\"longitude\"], new_lat, new_lon\n",
    "        )\n",
    "\n",
    "        fleet_df.at[idx, \"dest_lat\"] = new_lat\n",
    "        fleet_df.at[idx, \"dest_lon\"] = new_lon\n",
    "        fleet_df.at[idx, \"eta_min\"] = eta\n",
    "        fleet_df.at[idx, \"rerouted_at\"] = datetime.now(IST).strftime(\n",
    "            \"%Y-%m-%d %H:%M:%S\"\n",
    "        )\n",
    "\n",
    "        # Log rerouting event\n",
    "        log_entry = pd.DataFrame([{\n",
    "            \"vehicle_id\": row[\"vehicle_id\"],\n",
    "            \"risk_score\": row[\"risk_score\"],\n",
    "            \"reroute_reason\": row[\"reroute_reason\"],\n",
    "            \"new_eta_min\": eta,\n",
    "            \"distance_km\": distance,\n",
    "            \"rerouted_at\": fleet_df.at[idx, \"rerouted_at\"]\n",
    "        }])\n",
    "\n",
    "        log_entry.to_csv(\n",
    "            REROUTE_LOG,\n",
    "            mode=\"a\",\n",
    "            header=not os.path.exists(REROUTE_LOG),\n",
    "            index=False\n",
    "        )\n",
    "\n",
    "        map_path = generate_map(\n",
    "            row[\"latitude\"],\n",
    "            row[\"longitude\"],\n",
    "            new_lat,\n",
    "            new_lon,\n",
    "            row[\"vehicle_id\"]\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"[ALERT] Vehicle {row['vehicle_id']} rerouted | \"\n",
    "            f\"ETA: {eta} min | Distance: {distance} km\"\n",
    "        )\n",
    "        print(f\"[INFO] Route visualization saved at: {map_path}\")\n",
    "\n",
    "        reroute_count += 1\n",
    "\n",
    "    fleet_df.to_csv(FLEET_FILE, index=False)\n",
    "\n",
    "    if reroute_count:\n",
    "        print(f\"[INFO] Phase-4 completed with {reroute_count} reroute(s).\")\n",
    "    else:\n",
    "        print(\"[INFO] Phase-4 completed. No rerouting required.\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Continuous Execution Loop\n",
    "# -------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"[SYSTEM] Phase-4 Dynamic Rerouting service started.\")\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            run_dynamic_rerouting()\n",
    "            time.sleep(UPDATE_INTERVAL)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n[SYSTEM] Phase-4 service stopped by user.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec53b67-90f5-4864-af4f-fe09e9535247",
   "metadata": {},
   "source": [
    "# **PHASE-5 â€” MONITORING DASHBOARD**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fce5da-7f60-482c-8b51-8820260754f1",
   "metadata": {},
   "source": [
    "This phase provides a real-time visualization layer for fleet managers\n",
    "using Streamlit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269cb629-8b5c-447d-8647-9acf48024c30",
   "metadata": {},
   "source": [
    "### **Fleet Monitoring Dashboard**\n",
    "Displays:\n",
    "- Live GPS tracking\n",
    "- Incident predictions\n",
    "- Traffic heatmaps\n",
    "- Fleet utilization\n",
    "- Fuel consumption forecasts\n",
    "- Driver behavior alerts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "386e809f-97cb-4aba-9f8b-c9f31275db4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting phase5_dashboard/dashboard.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile phase5_dashboard/dashboard.py\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "from streamlit_folium import st_folium\n",
    "from streamlit_autorefresh import st_autorefresh\n",
    "import os\n",
    "import json\n",
    "\n",
    "# =====================================================\n",
    "# PAGE CONFIGURATION\n",
    "# =====================================================\n",
    "st.set_page_config(\n",
    "    page_title=\"ðŸšš AI Fleet Monitoring System\",\n",
    "    layout=\"wide\"\n",
    ")\n",
    "\n",
    "st.title(\"ðŸš› AI-Powered Fleet Optimization Dashboard\")\n",
    "st.caption(\"ðŸ“¡ Phase-5 | Real-Time Fleet Monitoring & Intelligence\")\n",
    "\n",
    "# =====================================================\n",
    "# SESSION STATE INITIALIZATION\n",
    "# =====================================================\n",
    "st.session_state.setdefault(\"paused\", False)\n",
    "st.session_state.setdefault(\"refresh_count\", 0)\n",
    "st.session_state.setdefault(\"map_center\", [17.3850, 78.4867])\n",
    "st.session_state.setdefault(\"map_zoom\", 10)\n",
    "st.session_state.setdefault(\"demo_mode\", True)\n",
    "\n",
    "# =====================================================\n",
    "# SIDEBAR NAVIGATION\n",
    "# =====================================================\n",
    "st.sidebar.header(\"ðŸ§­ Navigation\")\n",
    "page = st.sidebar.radio(\n",
    "    \"Select View ðŸ‘‡\",\n",
    "    [\n",
    "        \"ðŸ“ Live GPS & Routes\",\n",
    "        \"ðŸ”¥ Traffic Heatmap\",\n",
    "        \"âš ï¸ Incident Predictions\",\n",
    "        \"â›½ Fuel Forecast\",\n",
    "        \"ðŸš¨ Driver Alerts\",\n",
    "        \"ðŸ“‹ Fleet Assignments\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# =====================================================\n",
    "# LIVE CONTROLS\n",
    "# =====================================================\n",
    "st.sidebar.header(\"ðŸŽ›ï¸ Live Controls\")\n",
    "\n",
    "auto_refresh = st.sidebar.toggle(\"ðŸ”„ Auto Refresh\", value=True)\n",
    "\n",
    "refresh_sec = st.sidebar.slider(\n",
    "    \"â±ï¸ Refresh Interval (seconds)\",\n",
    "    min_value=5,\n",
    "    max_value=120,\n",
    "    value=30,\n",
    "    disabled=not auto_refresh\n",
    ")\n",
    "\n",
    "max_vehicles = st.sidebar.slider(\n",
    "    \"ðŸš— Active Vehicles\",\n",
    "    min_value=5,\n",
    "    max_value=50,\n",
    "    value=20,\n",
    "    step=5\n",
    ")\n",
    "\n",
    "if st.sidebar.button(\"â¸ï¸ Pause / â–¶ï¸ Resume\"):\n",
    "    st.session_state.paused = not st.session_state.paused\n",
    "\n",
    "# =====================================================\n",
    "# DEMO MODE CONTROL\n",
    "# =====================================================\n",
    "st.sidebar.header(\"ðŸ§ª Demo Controls\")\n",
    "st.session_state.demo_mode = st.sidebar.toggle(\n",
    "    \"ðŸ›£ï¸ Demo Mode (Force Reroutes)\",\n",
    "    value=st.session_state.demo_mode\n",
    ")\n",
    "\n",
    "# =====================================================\n",
    "# AUTO REFRESH HANDLING\n",
    "# =====================================================\n",
    "if auto_refresh and not st.session_state.paused:\n",
    "    st_autorefresh(interval=refresh_sec * 1000, key=\"fleet_refresh\")\n",
    "    st.session_state.refresh_count += 1\n",
    "\n",
    "fps = round(1 / refresh_sec, 2) if auto_refresh else 0\n",
    "\n",
    "st.sidebar.markdown(\"---\")\n",
    "st.sidebar.metric(\"ðŸ” Updates\", st.session_state.refresh_count)\n",
    "st.sidebar.metric(\"âš¡ Refresh Rate (FPS)\", fps)\n",
    "st.sidebar.metric(\n",
    "    \"ðŸŸ¢ System Status\",\n",
    "    \"Paused â¸ï¸\" if st.session_state.paused else \"Running â–¶ï¸\"\n",
    ")\n",
    "\n",
    "# =====================================================\n",
    "# CUSTOM STYLING\n",
    "# =====================================================\n",
    "st.markdown(\"\"\"\n",
    "<style>\n",
    ".metric-card {\n",
    "    background-color: #ffffff;\n",
    "    padding: 18px;\n",
    "    border-radius: 14px;\n",
    "    box-shadow: 0px 6px 18px rgba(0,0,0,0.12);\n",
    "}\n",
    ".metric-title {\n",
    "    font-size: 14px;\n",
    "    color: #6b7280;\n",
    "    font-weight: 600;\n",
    "}\n",
    ".metric-value {\n",
    "    font-size: 28px;\n",
    "    font-weight: 800;\n",
    "    color: #111827;\n",
    "}\n",
    "</style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "# =====================================================\n",
    "# FILE PATHS\n",
    "# =====================================================\n",
    "BASE_DIR = os.path.dirname(__file__)\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "STREAM_FILE = os.path.join(DATA_DIR, \"live_stream.csv\")\n",
    "PRED_FILE = os.path.join(DATA_DIR, \"live_predictions.csv\")\n",
    "FLEET_FILE = os.path.join(DATA_DIR, \"fleet_schedule.csv\")\n",
    "REROUTE_FILE = os.path.join(DATA_DIR, \"rerouting_logs.csv\")\n",
    "CONFIG_FILE = os.path.join(DATA_DIR, \"demo_config.json\")\n",
    "\n",
    "with open(CONFIG_FILE, \"w\") as f:\n",
    "    json.dump({\"DEMO_MODE\": st.session_state.demo_mode}, f)\n",
    "\n",
    "# =====================================================\n",
    "# SAFE CSV LOADER\n",
    "# =====================================================\n",
    "def safe_read_csv(path: str) -> pd.DataFrame:\n",
    "    if not os.path.exists(path):\n",
    "        return pd.DataFrame()\n",
    "    try:\n",
    "        return pd.read_csv(path, engine=\"python\", on_bad_lines=\"skip\")\n",
    "    except Exception:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "df_stream = safe_read_csv(STREAM_FILE)\n",
    "df_pred = safe_read_csv(PRED_FILE)\n",
    "df_fleet = safe_read_csv(FLEET_FILE)\n",
    "df_reroute = safe_read_csv(REROUTE_FILE)\n",
    "\n",
    "# =====================================================\n",
    "# DATA PREPARATION\n",
    "# =====================================================\n",
    "latest_pos = (\n",
    "    df_stream.groupby(\"vehicle_id\").last().reset_index().head(max_vehicles)\n",
    "    if not df_stream.empty else pd.DataFrame()\n",
    ")\n",
    "\n",
    "latest_pred = (\n",
    "    df_pred.groupby(\"vehicle_id\").last().reset_index().head(max_vehicles)\n",
    "    if not df_pred.empty else pd.DataFrame()\n",
    ")\n",
    "\n",
    "for col in [\"vehicle_id\", \"latitude\", \"longitude\", \"speed\", \"traffic_index\"]:\n",
    "    if col not in latest_pos.columns:\n",
    "        latest_pos[col] = 0\n",
    "\n",
    "for col in [\"vehicle_id\",\"accident_risk\",\"breakdown_risk\",\"slowdown_risk\",\"route_blockage_risk\"]:\n",
    "    if col not in latest_pred.columns:\n",
    "        latest_pred[col] = 0.0\n",
    "\n",
    "latest_pos = latest_pos[\n",
    "    (latest_pos[\"latitude\"] != 0) & (latest_pos[\"longitude\"] != 0)\n",
    "]\n",
    "\n",
    "# =====================================================\n",
    "# KPI CARD COMPONENT\n",
    "# =====================================================\n",
    "def metric_card(container, title, value, icon):\n",
    "    container.markdown(f\"\"\"\n",
    "    <div class=\"metric-card\">\n",
    "        <div class=\"metric-title\">{icon} {title}</div>\n",
    "        <div class=\"metric-value\">{value}</div>\n",
    "    </div>\n",
    "    \"\"\", unsafe_allow_html=True)\n",
    "\n",
    "# =====================================================\n",
    "# MAP GENERATION\n",
    "# =====================================================\n",
    "def generate_map():\n",
    "    fmap = folium.Map(\n",
    "        location=st.session_state.map_center,\n",
    "        zoom_start=st.session_state.map_zoom,\n",
    "        control_scale=True\n",
    "    )\n",
    "\n",
    "    for _, row in latest_pos.iterrows():\n",
    "        risk_series = latest_pred.loc[\n",
    "            latest_pred[\"vehicle_id\"] == row[\"vehicle_id\"],\n",
    "            \"accident_risk\"\n",
    "        ]\n",
    "        risk = float(risk_series.values[0]) if not risk_series.empty else 0.0\n",
    "        color = \"green\" if risk < 0.4 else \"orange\" if risk < 0.75 else \"red\"\n",
    "\n",
    "        folium.Marker(\n",
    "            [row[\"latitude\"], row[\"longitude\"]],\n",
    "            popup=f\"\"\"\n",
    "            ðŸšš <b>Vehicle:</b> {row['vehicle_id']}<br>\n",
    "            âš¡ <b>Speed:</b> {row['speed']} km/h<br>\n",
    "            âš ï¸ <b>Accident Risk:</b> {risk:.2f}\n",
    "            \"\"\",\n",
    "            icon=folium.Icon(color=color, icon=\"truck\", prefix=\"fa\")\n",
    "        ).add_to(fmap)\n",
    "\n",
    "    return fmap\n",
    "\n",
    "# =====================================================\n",
    "# PAGE RENDERING\n",
    "# =====================================================\n",
    "if page == \"ðŸ“ Live GPS & Routes\":\n",
    "    st.subheader(\"ðŸ“¡ Live Vehicle Tracking\")\n",
    "\n",
    "    map_data = st_folium(\n",
    "        generate_map(),\n",
    "        width=1300,\n",
    "        height=550,\n",
    "        returned_objects=[\"center\", \"zoom\"]\n",
    "    )\n",
    "\n",
    "    \n",
    "    if map_data:\n",
    "        if map_data.get(\"center\"):\n",
    "            st.session_state.map_center = [\n",
    "                map_data[\"center\"][\"lat\"],\n",
    "                map_data[\"center\"][\"lng\"]\n",
    "            ]\n",
    "        if map_data.get(\"zoom\"):\n",
    "            st.session_state.map_zoom = map_data[\"zoom\"]\n",
    "\n",
    "elif page == \"ðŸ”¥ Traffic Heatmap\":\n",
    "    st.subheader(\"ðŸ”¥ Traffic Density Heatmap\")\n",
    "    heat_map = folium.Map(location=st.session_state.map_center, zoom_start=st.session_state.map_zoom)\n",
    "    HeatMap(latest_pos[[\"latitude\",\"longitude\",\"traffic_index\"]].values.tolist(), radius=20).add_to(heat_map)\n",
    "    st_folium(heat_map, width=1300, height=520)\n",
    "\n",
    "\n",
    "elif page == \"âš ï¸ Incident Predictions\":\n",
    "    # =====================================================\n",
    "    # AVERAGE INCIDENT PREDICTIONS (FLEET LEVEL)\n",
    "    # =====================================================\n",
    "    st.subheader(\"ðŸ“ˆ Average Incident Predictions\")\n",
    "    if latest_pred.empty:\n",
    "        st.info(\"No prediction data available\")\n",
    "    else:\n",
    "        a1, a2, a3, a4 = st.columns(4)\n",
    "        avg_accident = latest_pred[\"accident_risk\"].mean() * 100\n",
    "        avg_breakdown = latest_pred[\"breakdown_risk\"].mean() * 100\n",
    "        avg_slowdown = latest_pred[\"slowdown_risk\"].mean() * 100\n",
    "        avg_blockage = latest_pred[\"route_blockage_risk\"].mean() * 100\n",
    "        metric_card(a1, \"Accident Risk\", f\"{avg_accident:.1f}%\", \"ðŸš¨\")\n",
    "        metric_card(a2, \"Breakdown Risk\", f\"{avg_breakdown:.1f}%\", \"ðŸ› \")\n",
    "        metric_card(a3, \"Slowdown Risk\", f\"{avg_slowdown:.1f}%\", \"ðŸ¢\")\n",
    "        metric_card(a4, \"Route Blockage Risk\", f\"{avg_blockage:.1f}%\", \"â›”\")\n",
    "\n",
    "    st.subheader(\"ðŸ“Š Incident Risk Predictions\")\n",
    "    st.dataframe(latest_pred, use_container_width=True)\n",
    "\n",
    "\n",
    "elif page == \"â›½ Fuel Forecast\":\n",
    "    st.subheader(\"â›½ Fuel Consumption Forecast\")\n",
    "    latest_pos[\"fuel_estimate\"] = latest_pos[\"speed\"]*0.05 + latest_pos[\"traffic_index\"]*2\n",
    "    st.line_chart(latest_pos.set_index(\"vehicle_id\")[\"fuel_estimate\"])\n",
    "\n",
    "elif page == \"ðŸš¨ Driver Alerts\":\n",
    "    st.subheader(\"ðŸš¨ Driver Alerts (Action Required)\")\n",
    "\n",
    "    if latest_pos.empty:\n",
    "        st.info(\"No alerts available at this time.\")\n",
    "    else:\n",
    "        # Merge live GPS data with prediction data\n",
    "        alerts = latest_pos.merge(\n",
    "            latest_pred,\n",
    "            on=\"vehicle_id\",\n",
    "            how=\"left\"\n",
    "        )\n",
    "\n",
    "        # Fill missing prediction values safely\n",
    "        alerts[[\n",
    "            \"accident_risk\",\n",
    "            \"breakdown_risk\",\n",
    "            \"slowdown_risk\",\n",
    "            \"route_blockage_risk\"\n",
    "        ]] = alerts[[\n",
    "            \"accident_risk\",\n",
    "            \"breakdown_risk\",\n",
    "            \"slowdown_risk\",\n",
    "            \"route_blockage_risk\"\n",
    "        ]].fillna(0.0)\n",
    "\n",
    "        # Default severity\n",
    "        alerts[\"severity\"] = \"LOW\"\n",
    "\n",
    "        # Medium severity conditions\n",
    "        alerts.loc[\n",
    "            alerts[\"traffic_index\"] > 1.3,\n",
    "            \"severity\"\n",
    "        ] = \"MEDIUM\"\n",
    "\n",
    "        # High severity conditions (critical)\n",
    "        alerts.loc[\n",
    "            (alerts[\"traffic_index\"] > 1.5) |\n",
    "            (alerts[\"speed\"] > 90) |\n",
    "            (alerts[\"accident_risk\"] > 0.75),\n",
    "            \"severity\"\n",
    "        ] = \"HIGH\"\n",
    "\n",
    "        # Filter only actionable alerts\n",
    "        alerts = alerts[alerts[\"severity\"] != \"LOW\"]\n",
    "\n",
    "        # KPI: Active alerts count\n",
    "        st.metric(\"ðŸš¨ Active Alerts\", len(alerts))\n",
    "\n",
    "        if alerts.empty:\n",
    "            st.success(\"No critical driver alerts ðŸŽ‰\")\n",
    "        else:\n",
    "            # Human-friendly alert labels\n",
    "            alerts[\"alert\"] = alerts[\"severity\"].map({\n",
    "                \"MEDIUM\": \"ðŸŸ  Caution\",\n",
    "                \"HIGH\": \"ðŸ”´ Immediate Action\"\n",
    "            })\n",
    "\n",
    "            # Display alerts sorted by risk priority\n",
    "            st.dataframe(\n",
    "                alerts[\n",
    "                    [\n",
    "                        \"vehicle_id\",\n",
    "                        \"speed\",\n",
    "                        \"traffic_index\",\n",
    "                        \"accident_risk\",\n",
    "                        \"alert\"\n",
    "                    ]\n",
    "                ].sort_values(\n",
    "                    by=\"accident_risk\",\n",
    "                    ascending=False\n",
    "                ),\n",
    "                use_container_width=True\n",
    "            )\n",
    "\n",
    "            st.warning(\n",
    "                \"âš ï¸ High-risk alerts require immediate attention to prevent accidents or delays.\"\n",
    "            )\n",
    "\n",
    "elif page == \"ðŸ“‹ Fleet Assignments\":\n",
    "    st.subheader(\"ðŸ“‹ Fleet Schedule & Assignments\")\n",
    "    st.dataframe(df_fleet, use_container_width=True)\n",
    "\n",
    "# =====================================================\n",
    "# FLEET SUMMARY\n",
    "# =====================================================\n",
    "st.subheader(\"ðŸ“Š Fleet Summary\")\n",
    "\n",
    "c1, c2, c3, c4 = st.columns(4)\n",
    "\n",
    "metric_card(c1, \"Active Vehicles\", latest_pos[\"vehicle_id\"].nunique(), \"ðŸš—\")\n",
    "metric_card(c2, \"High-Risk Vehicles\", (latest_pred[\"accident_risk\"] >= 0.75).sum(), \"âš ï¸\")\n",
    "metric_card(c3, \"Fleet Utilization\", \"Optimized âœ…\", \"ðŸ“ˆ\")\n",
    "metric_card(c4, \"Reroutes Triggered\", len(df_reroute), \"ðŸ›£ï¸\")\n",
    "\n",
    "st.success(\"âœ… Phase-5 Fleet Monitoring Dashboard is running successfully ðŸš€\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b1f049-23bb-4d58-b4f6-157509a0c802",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
